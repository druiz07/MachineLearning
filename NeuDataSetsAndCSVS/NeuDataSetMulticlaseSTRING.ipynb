{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e532e6b",
   "metadata": {},
   "source": [
    "\n",
    "**Lectura de un DATASET de MULTICLASIFICACION / INICIALIZACION DE LA RED CON NEURONAS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0565b8dc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             B         C         D         E         F         G         H  \\\n",
      "0     6.520910  4.611073  6.489857  4.588929  15.98893  0.275700  3.105008   \n",
      "1     6.520907  4.611071  6.489859  4.588931  15.98893  0.275717  3.105008   \n",
      "2     6.520906  4.611070  6.489861  4.588932  15.98893  0.275722  3.105007   \n",
      "3     6.520902  4.611067  6.489865  4.588934  15.98894  0.275743  3.105007   \n",
      "4     6.520895  4.611062  6.489872  4.588939  15.98894  0.275746  3.105007   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "2906  9.121757  5.322410  4.835673  4.017130  15.33107  0.279167 -9.927512   \n",
      "2907  8.469483  5.462036  4.905059  3.773489  15.15157  0.279184 -8.394883   \n",
      "2908  7.433750  5.428230  5.521473  3.776682  15.18696  0.279201 -7.033270   \n",
      "2909  6.143655  5.248931  7.409981  4.148458  15.49571  0.279219 -5.558267   \n",
      "2910  4.994212  4.936121 -1.000000  4.964962  16.07087  0.279219 -4.207523   \n",
      "\n",
      "              I  \n",
      "0      0.419318  \n",
      "1      0.437750  \n",
      "2      0.445260  \n",
      "3      0.506243  \n",
      "4      0.600826  \n",
      "...         ...  \n",
      "2906  22.004520  \n",
      "2907  22.108350  \n",
      "2908  22.200090  \n",
      "2909  22.301710  \n",
      "2910  22.400820  \n",
      "\n",
      "[2911 rows x 8 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from RedNeu import cost, backprop , predict,initialize_parameters,update_parameters\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder,MinMaxScaler,LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# En caso de solo tener un data set /Habria que mencionar que se podria estar usando kfold validation\n",
    "\n",
    "##filepath=\"kartMULTI.csv\"\n",
    "##data =  pd.read_csv(filepath)\n",
    "##X_train= data.drop(\"action\", axis=1)\n",
    "##VALUES= data[\"action\"]\n",
    "# X_train, X_test, y_train_split, y_test_split = train_test_split(X, VALUES, test_size=0.30, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Lectura de datos en formato txt\n",
    "file_path_train = \"kartTrainMULTI.csv\"\n",
    "file_path_test = \"kartTestMULTI.csv\"\n",
    "\n",
    "\n",
    "# Cargar los datos de entrenamiento\n",
    "data_train = pd.read_csv(file_path_train)\n",
    "data_test = pd.read_csv(file_path_test)\n",
    "\n",
    "# Separar las características (X) y la variable objetivo (y)\n",
    "X_train = data_train.drop(\"action\", axis=1)\n",
    "X_test = data_test.drop(\"action\", axis=1)\n",
    "X_train = X_train.drop(\"A\", axis=1)\n",
    "X_test = X_test.drop(\"A\", axis=1)\n",
    "print (X_train)\n",
    "\n",
    "y_train_split = data_train[\"action\"]\n",
    "y_test_split = data_test[\"action\"]\n",
    "\n",
    "\n",
    "#SOLO SI ES MULTICLASE Y NO CLASIFICAION BINARIA \n",
    "# Convertir y_train_split a una matriz de etiquetas one-hot\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "Y_train_onehot = encoder.fit_transform(y_train_split.to_numpy().reshape(-1, 1))\n",
    "Y_test_onehot = encoder.fit_transform(y_test_split.to_numpy().reshape(-1, 1))\n",
    "\n",
    "# Añadir el sesgo a los conjuntos de entrenamiento y prueba\n",
    "X_train_with_bias = np.hstack([np.ones((X_train.shape[0], 1)), X_train])\n",
    "X_test_with_bias = np.hstack([np.ones((X_test.shape[0], 1)), X_test])\n",
    "\n",
    "\n",
    "\n",
    "# El numero de neuronas de entrada siempre es igual a los parametros de entrada\n",
    "# La salida igual, tenemos que la salida es la calidad de 0-10 así que 10 neuronas de salida\n",
    "##Tantas neuronas de entrada como datos , y de salida si es binaria 2( o 1 o 0) y si es multi las que tenga y\n",
    "layer_sizes = [X_train.shape[1], 10, Y_train_onehot.shape[1]]  # Ajusta el número de neuronas según sea necesario\n",
    "theta_list = initialize_parameters(layer_sizes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8985d564",
   "metadata": {},
   "source": [
    "**ENTRENAMIENTO DEL MODELO MLP**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "14f1e5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Ajustar hiperparámetros\n",
    "lambdaValue = 0.025  # Experimenta con diferentes valores\n",
    "alpha = 0.1  # Experimenta con diferentes valores\n",
    "iterations = 1200  # Experimenta con diferentes valores\n",
    "\n",
    "# Paso 3: Entrenamiento del perceptrón multicapa\n",
    "for _ in range(iterations):\n",
    "    J, grad = backprop(theta_list, X_train_with_bias, Y_train_onehot, lambdaValue)\n",
    "    # Actualizar parámetros\n",
    "    update_parameters(theta_list, grad, alpha)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fde98c7",
   "metadata": {},
   "source": [
    "**Prediccion de los datos y calculo de metricas de medida de rendimiento**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d5a620b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\danie\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\danie\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Paso 4: Evaluación del perceptrón multicapa\n",
    "predictions_test = predict(theta_list, X_test_with_bias)\n",
    "\n",
    "# Obtener las etiquetas predichas (como índices de la clase con probabilidad máxima)\n",
    "predicted_labels_test = np.argmax(predictions_test, axis=1)\n",
    "# Obtener las etiquetas reales\n",
    "true_labels_test = np.argmax(Y_test_onehot, axis=1)\n",
    "\n",
    "\n",
    "accuracy_test = accuracy_score(true_labels_test, predicted_labels_test)\n",
    "# Calcular la matriz de confusión\n",
    "conf_matrix_test = confusion_matrix(true_labels_test, predicted_labels_test)\n",
    "\n",
    "# Obtener True Positives (Verdaderos Positivos) y False Positives (Falsos Positivos) de la matriz de confusión\n",
    "##ESTO SE HACE ASI POR QUE ES CLASIFICACION BINARIA ,EN ESTE EJEMPLO:  O PERSONA O CABALLO \n",
    "##SI ESTO FUESE MULTICLASE HABRIA QUE HACER UNA CLASE POSITIVA PARA CADA ETIQUETA\n",
    "# Obtener True Positives (Verdaderos Positivos) y False Positives (Falsos Positivos) de la matriz de confusión\n",
    "true_positives_class_1 = conf_matrix_test[1, 1]  # Posición [1, 1] para la clase positiva (1)\n",
    "false_positives_class_1 = conf_matrix_test[0, 1]  # Posición [0, 1] para la clase negativa (0) clasificada como positiva (1)\n",
    "# Obtener True Negatives (Verdaderos Negativos) y False Negatives (Falsos Negativos) de la matriz de confusión\n",
    "true_negatives_class_0 = conf_matrix_test[0, 0]  # Posición [0, 0] para la clase negativa (0)\n",
    "false_negatives_class_0 = conf_matrix_test[1, 0]  # Posición [1, 0] para la clase positiva (1) clasificada como negativa (0)\n",
    "\n",
    "\n",
    "\n",
    "# Calcular Precision para la clase positiva (1)\n",
    "precision_class_1 = true_positives_class_1 / (true_positives_class_1 + false_positives_class_1) if (true_positives_class_1 + false_positives_class_1) > 0 else 0\n",
    "# Calcular Precision para la clase negativa (0)\n",
    "precision_class_0 = true_negatives_class_0 / (true_negatives_class_0 + false_negatives_class_0) if (true_negatives_class_0 + false_negatives_class_0) > 0 else 0\n",
    "\n",
    "\n",
    "# Definir nombres de las clases\n",
    "class_names = ['ACCELERATE', 'LEFT_ACC','RIGHT_ACCELERATE']  # Reemplaza con los nombres específicos de tus clases\n",
    "# Calcular el classification_report\n",
    "report = classification_report(true_labels_test, predicted_labels_test,target_names=class_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a968c709",
   "metadata": {},
   "source": [
    "**IMPRESION DE LOS RESULTADOS OBTENIDOS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d8a34aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Costo de la red neuronal en entrenamiento: 1.16%\n",
      "Costo de la red neuronal en prueba: 1.13%\n",
      "Accuracy: 71.64%\n",
      "Matriz de Confusión en Test:\n",
      "[[732 279   0]\n",
      " [267 690   0]\n",
      " [ 13   4   0]]\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      ACCELERATE       0.72      0.72      0.72      1011\n",
      "        LEFT_ACC       0.71      0.72      0.72       957\n",
      "RIGHT_ACCELERATE       0.00      0.00      0.00        17\n",
      "\n",
      "        accuracy                           0.72      1985\n",
      "       macro avg       0.48      0.48      0.48      1985\n",
      "    weighted avg       0.71      0.72      0.71      1985\n",
      "\n",
      "\n",
      "Explicaciones:\n",
      "Precision: Es la proporción de instancias clasificadas como positivas que son realmente positivas.\n",
      "Recall: Es la proporción de instancias positivas que fueron correctamente clasificadas como positivas.\n",
      "F1-score: Es la media armónica ponderada de precision y recall. Es útil cuando hay desbalance de clases.\n",
      "Support: Es el número real de ocurrencias de la clase en el conjunto de prueba.\n",
      "Accuracy: Es la proporción de instancias correctamente clasificadas en el conjunto de prueba.\n",
      "Macro avg: Es el promedio no ponderado de precision, recall y f1-score para todas las clases.\n",
      "Weighted avg: Es el promedio ponderado por el soporte (número de instancias) de precision, recall y f1-score.\n"
     ]
    }
   ],
   "source": [
    "print(f'Costo de la red neuronal en entrenamiento: {cost(theta_list, X_train_with_bias, Y_train_onehot, lambdaValue):.2f}%')\n",
    "print(f'Costo de la red neuronal en prueba: {cost(theta_list, X_test_with_bias, Y_test_onehot, lambdaValue):.2f}%')\n",
    "print(f'Accuracy: {accuracy_test * 100:.2f}%')\n",
    "# Imprimir la matriz de confusión\n",
    "print(\"Matriz de Confusión en Test:\")\n",
    "print(conf_matrix_test)\n",
    "# SE HACE ASI POR QUE SOLO HAY DOS CLASES ES BINARIA , SI FUESE MULTICLASE PONRIAMOS LAS QUE NOS INTERESEN\n",
    "# Imprimir los  reportes obtenidos sobre las distintas clases \n",
    "print(report)\n",
    "print(\"\\nExplicaciones:\")\n",
    "print(\"Precision: Es la proporción de instancias clasificadas como positivas que son realmente positivas.\")\n",
    "print(\"Recall: Es la proporción de instancias positivas que fueron correctamente clasificadas como positivas.\")\n",
    "print(\"F1-score: Es la media armónica ponderada de precision y recall. Es útil cuando hay desbalance de clases.\")\n",
    "print(\"Support: Es el número real de ocurrencias de la clase en el conjunto de prueba.\")\n",
    "print(\"Accuracy: Es la proporción de instancias correctamente clasificadas en el conjunto de prueba.\")\n",
    "print(\"Macro avg: Es el promedio no ponderado de precision, recall y f1-score para todas las clases.\")\n",
    "print(\"Weighted avg: Es el promedio ponderado por el soporte (número de instancias) de precision, recall y f1-score.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b8175dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados del Perceptrón Multicapa de Scikit-Learn:\n",
      "Accuracy: 73.30%\n",
      "Matriz de Confusión Test:\n",
      "[[753 258   0]\n",
      " [255 702   0]\n",
      " [ 13   4   0]]\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      ACCELERATE       0.74      0.74      0.74      1011\n",
      "        LEFT_ACC       0.73      0.73      0.73       957\n",
      "RIGHT_ACCELERATE       0.00      0.00      0.00        17\n",
      "\n",
      "        accuracy                           0.73      1985\n",
      "       macro avg       0.49      0.49      0.49      1985\n",
      "    weighted avg       0.73      0.73      0.73      1985\n",
      "\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      ACCELERATE       0.72      0.72      0.72      1011\n",
      "        LEFT_ACC       0.71      0.72      0.72       957\n",
      "RIGHT_ACCELERATE       0.00      0.00      0.00        17\n",
      "\n",
      "        accuracy                           0.72      1985\n",
      "       macro avg       0.48      0.48      0.48      1985\n",
      "    weighted avg       0.71      0.72      0.71      1985\n",
      "\n",
      "\n",
      "Explicaciones:\n",
      "Precision: Es la proporción de instancias clasificadas como positivas que son realmente positivas.\n",
      "Recall: Es la proporción de instancias positivas que fueron correctamente clasificadas como positivas.\n",
      "F1-score: Es la media armónica ponderada de precision y recall. Es útil cuando hay desbalance de clases.\n",
      "Support: Es el número real de ocurrencias de la clase en el conjunto de prueba.\n",
      "Accuracy: Es la proporción de instancias correctamente clasificadas en el conjunto de prueba.\n",
      "Macro avg: Es el promedio no ponderado de precision, recall y f1-score para todas las clases.\n",
      "Weighted avg: Es el promedio ponderado por el soporte (número de instancias) de precision, recall y f1-score.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\danie\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\danie\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "##PERCEPTRON DE SKLEARN\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "##IMPORTANTE : SOBRE ESTE MODELO NO AÑADIMOS EL SESGO \n",
    "##EL MODELO INTEPRETA AUTOMATICAMENTE EL NUMERO DE CAPAS DE ENTRADA Y DE SALIDA \n",
    "\n",
    "mlp_sklearn = MLPClassifier(\n",
    "    hidden_layer_sizes=(10,),  # Ajustar el número de neuronas en la capa oculta según sea necesario\n",
    "    activation='logistic',        # Usar la función de activación\n",
    "    max_iter=1000,             # Número máximo de iteraciones\n",
    "    alpha=0.01,               # Término de regularización\n",
    "    learning_rate_init=0.025,   # Tasa de aprendizaje inicial\n",
    "    random_state=42\n",
    ")\n",
    "mlp_sklearn.fit(X_train, Y_train_onehot)  # Ajustar el modelo\n",
    "\n",
    "# Hacer predicciones en el conjunto de prueba\n",
    "predictions_sklearn = mlp_sklearn.predict(X_test)\n",
    "# Obtener las etiquetas predichas (como índices de la clase con probabilidad máxima)\n",
    "predicted_labels_test = np.argmax(predictions_sklearn, axis=1)\n",
    "# Obtener las etiquetas reales\n",
    "true_labels_test = np.argmax(Y_test_onehot, axis=1)\n",
    "\n",
    "# Calcular métricas de evaluación del modelo de Scikit-Learn\n",
    "accuracy_sklearn = accuracy_score(true_labels_test, predicted_labels_test)\n",
    "conf_matrix_sklearn = confusion_matrix(true_labels_test, predicted_labels_test)\n",
    "report_sklearn = classification_report(true_labels_test, predicted_labels_test, target_names=class_names)\n",
    "\n",
    "\n",
    "print(\"\\nResultados del Perceptrón Multicapa de Scikit-Learn:\")\n",
    "print(f'Accuracy: {accuracy_sklearn * 100:.2f}%')\n",
    "print(\"Matriz de Confusión Test:\")\n",
    "print(conf_matrix_sklearn)\n",
    "print(report_sklearn)\n",
    "print(report)\n",
    "print(\"\\nExplicaciones:\")\n",
    "print(\"Precision: Es la proporción de instancias clasificadas como positivas que son realmente positivas.\")\n",
    "print(\"Recall: Es la proporción de instancias positivas que fueron correctamente clasificadas como positivas.\")\n",
    "print(\"F1-score: Es la media armónica ponderada de precision y recall. Es útil cuando hay desbalance de clases.\")\n",
    "print(\"Support: Es el número real de ocurrencias de la clase en el conjunto de prueba.\")\n",
    "print(\"Accuracy: Es la proporción de instancias correctamente clasificadas en el conjunto de prueba.\")\n",
    "print(\"Macro avg: Es el promedio no ponderado de precision, recall y f1-score para todas las clases.\")\n",
    "print(\"Weighted avg: Es el promedio ponderado por el soporte (número de instancias) de precision, recall y f1-score.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d186ea",
   "metadata": {},
   "source": [
    "# Explicaciones sobre el uso de la red neuronal\n",
    "\n",
    "Este código implementa una red neuronal para un problema de clasificación. A continuación, explicaré las funciones y parámetros:\n",
    "\n",
    "## 1. Funciones de activación:\n",
    "\n",
    "- `sigmoid(z)`: Devuelve el valor de la función sigmoide para la entrada 'z'.\n",
    "- `sigmoid_gradient(z)`: Devuelve la derivada de la función sigmoide para la entrada 'z'.\n",
    "\n",
    "## 2. Función de costo con regularización:\n",
    "\n",
    "- `cost(theta_list, X, Y, lambda_)`: Calcula la función de costo para la red neuronal. Utiliza la entropía cruzada para la clasificación binaria y agrega términos de regularización para evitar el sobreajuste.\n",
    "\n",
    "## 3. Función de predicción:\n",
    "\n",
    "- `predict(theta_list, X)`: Realiza la propagación hacia adelante y devuelve las predicciones de la red neuronal.\n",
    "\n",
    "## 4. Inicialización de parámetros:\n",
    "\n",
    "- `initialize_parameters(layer_sizes)`: Inicializa los pesos de la red neuronal de manera aleatoria. 'layer_sizes' especifica el número de neuronas en cada capa.\n",
    "\n",
    "## 5. Propagación hacia adelante:\n",
    "\n",
    "- `forward_propagation(X, theta_list)`: Realiza la propagación hacia adelante y devuelve las activaciones y valores de 'z' para cada capa.\n",
    "\n",
    "## 6. Actualización de parámetros:\n",
    "\n",
    "- `update_parameters(theta_list, grads, learning_rate)`: Actualiza los pesos de la red neuronal utilizando el descenso de gradiente.\n",
    "\n",
    "## 7. Propagación hacia atrás (Backpropagation):\n",
    "\n",
    "- `backprop(theta_list, X, y, lambda_)`: Calcula el costo y los gradientes utilizando la propagación hacia atrás. Los gradientes se utilizan para la actualización de parámetros.\n",
    "\n",
    "## Configuración de parámetros:\n",
    "\n",
    "- `layer_sizes`: Se define como '[n_input, n_output]', donde 'n_input' es el número de características de entrada y 'n_output' es el número de neuronas en la capa de salida.\n",
    "- `lambda_`: Parámetro de regularización. Controla la importancia de los términos de regularización en la función de costo.\n",
    "- `learning_rate`: Tasa de aprendizaje para el descenso de gradiente.\n",
    "- `iterations`: Número de iteraciones del descenso de gradiente.\n",
    "**Tasa de Aprendizaje (Learning Rate):**\n",
    "\n",
    "La tasa de aprendizaje es un parámetro que determina qué tan grandes son los pasos que la red neuronal toma durante el descenso de gradiente. Aquí hay algunas consideraciones al subir o bajar la tasa de aprendizaje:\n",
    "\n",
    "- *Subir la Tasa de Aprendizaje:*\n",
    "  - **Ventajas:** Puede conducir a convergencia más rápida durante el entrenamiento.\n",
    "  - **Desventajas:** Si la tasa de aprendizaje es demasiado alta, el descenso de gradiente puede oscilar o divergir, lo que significa que los pesos pueden no converger a un mínimo global, y el entrenamiento puede volverse inestable.\n",
    "\n",
    "- *Bajar la Tasa de Aprendizaje:*\n",
    "  - **Ventajas:** Puede mejorar la estabilidad del entrenamiento y permitir una convergencia más suave.\n",
    "  - **Desventajas:** Demorará más en converger, especialmente en conjuntos de datos grandes. Si la tasa de aprendizaje es demasiado baja, el modelo puede tardar demasiado en aprender y puede quedar atrapado en mínimos locales.\n",
    "\n",
    "**Recomendaciones:**\n",
    "- Comienza con una tasa de aprendizaje moderada y ajústala según sea necesario.\n",
    "- Utiliza técnicas como la disminución adaptativa del learning rate para ajustar dinámicamente la tasa de aprendizaje durante el entrenamiento.\n",
    "\n",
    "---\n",
    "\n",
    "**Parámetro de Regularización (Alfa o Lambda):**\n",
    "\n",
    "El parámetro de regularización controla la magnitud de la penalización aplicada a los pesos de la red para prevenir el sobreajuste. Aquí hay algunas consideraciones al subir o bajar el parámetro de regularización:\n",
    "\n",
    "- *Subir el Parámetro de Regularización:*\n",
    "  - **Ventajas:** Puede ayudar a prevenir el sobreajuste al penalizar pesos grandes.\n",
    "  - **Desventajas:** Si es demasiado alto, puede llevar a una supresión excesiva de los pesos, haciendo que el modelo sea demasiado simple y no capte patrones complejos en los datos.\n",
    "\n",
    "- *Bajar el Parámetro de Regularización:*\n",
    "  - **Ventajas:** Puede permitir que el modelo capture patrones más complejos en los datos.\n",
    "  - **Desventajas:** Aumenta el riesgo de sobreajuste, especialmente en conjuntos de datos pequeños o cuando la complejidad del modelo es alta.\n",
    "\n",
    "**Recomendaciones:**\n",
    "- Utilizo validación cruzada para encontrar el valor óptimo del parámetro de regularización.\n",
    "- Experimento con valores en una escala logarítmica (0.1, 0.01, 0.001, etc.) para encontrar el equilibrio adecuado entre regularización y capacidad del modelo.\n",
    "\n",
    "## Uso de la codificación one-hot para problemas multiclase:\n",
    "\n",
    "- Cuando se enfrenta a un problema de clasificación multiclase, la codificación one-hot se aplica a las etiquetas de clase. Esta codificación convierte las etiquetas de clase en vectores binarios, donde cada vector representa una clase única y la posición del 1 indica la clase.\n",
    "- La función de costo y las funciones de actualización de parámetros han sido diseñadas para manejar problemas de clasificación binaria y multiclase mediante el uso de one-hot encoding.\n",
    "\n",
    "## Análisis:\n",
    "\n",
    "- La red neuronal es adecuada tanto para problemas de clasificación binaria como multiclase.\n",
    "- La codificación one-hot aborda eficazmente el problema multiclase y permite que la red clasifique instancias en más de dos clases.\n",
    "- Es importante ajustar la tasa de aprendizaje y el término de regularización para obtener un rendimiento óptimo en problemas multiclase.\n",
    "- Las redes neuronales, especialmente las más profundas, tienden a necesitar grandes cantidades de datos para entrenarse de manera efectiva. Si tienes un conjunto de datos relativamente pequeño, podrías enfrentar problemas de sobreajuste.\n",
    "- La red neuronal también se puede mejorar mediante el uso de validación cruzada.\n",
    "\n",
    "## Esta configuración de la red resuelve problemas de tres tipos:\n",
    "\n",
    "1. **Problema Multiclase String**: Ejemplo de clasificación de acciones (\"Action\", \"Accelerate\", etc.).\n",
    "2. **Problema Multiclase Numérico**: Ejemplo de clasificación de calidad del vino (0-9).\n",
    "3. **Problemas de Clasificación Binaria**: Ejemplo de clasificación de si el vino es bueno o no.\n",
    "4.  **Problema de Clasificacion de Imagenes** Otro tipo de problema de  clasificacion , en archivos . mat\n",
    "\n",
    "### Modelos Recomendados:\n",
    "# 1. Clasificación Binaria: Redes Neuronales con Capas Ocultas\n",
    "## Motivos:\n",
    "- **Aprendizaje de Representaciones Complejas:** Las redes neuronales permiten aprender representaciones no lineales y complejas de los datos. En problemas de clasificación binaria, donde las relaciones entre las características y la salida pueden ser no lineales, las capas ocultas de la red neuronal pueden capturar patrones más sofisticados.\n",
    "- **Extracción de Características Abstractas:** Las capas ocultas posibilitan la extracción de características más abstractas y complejas. Esto es esencial cuando las relaciones subyacentes en los datos no son evidentes y requieren representaciones más profundas para su comprensión.\n",
    "- **Manejo de Patrones No Lineales:** Las redes neuronales son especialmente aptas para manejar patrones no lineales en los datos. En problemas de clasificación binaria, donde las decisiones de clasificación pueden estar basadas en relaciones complejas, las redes neuronales pueden superar las limitaciones de modelos más simples como la regresión logística.\n",
    "\n",
    "# 2. Clasificación de Imagenes: Redes Neuronales Convolucionales (CNN)\n",
    "## Motivos:\n",
    "- **Efectividad en Clasificación de Imágenes:** Las CNN son altamente efectivas en la clasificación de datos de imágenes. Están diseñadas para aprender jerarquías de características, desde características simples hasta más complejas, lo que es esencial para interpretar datos visuales.\n",
    "- **Captura de Patrones Espaciales y de Textura:** Las CNN son capaces de capturar patrones espaciales y de textura en datos bidimensionales como imágenes. La arquitectura convolucional permite la extracción eficiente de características locales, lo que es crucial en problemas de clasificación de texto.\n",
    "- **Reducción de Parámetros con Compartición de Pesos:** La arquitectura convolucional reduce el número de parámetros al compartir pesos. Esto es beneficioso en conjuntos de datos grandes como imágenes, donde se pueden aprender patrones locales que son útiles en diferentes partes de la imagen.\n",
    "\n",
    "# 3. Clasificación Multiclase : Regresión Logística o Redes Neuronales FeedFoward\n",
    "## Motivos:\n",
    "- **Eficiencia de la Regresión Logística:** La regresión logística es simple y efectiva para problemas de clasificación multiclase. Cuando la relación entre las características y la salida es relativamente lineal, la regresión logística puede ser una opción eficiente.\n",
    "- **Adaptabilidad de las Redes Neuronales:** Las redes neuronales pueden adaptarse mejor a patrones no lineales y relaciones complejas en comparación con la regresión logística. Si el problema presenta una complejidad significativa, las redes neuronales pueden capturar mejor estas relaciones.\n",
    "- **Elección Dependiendo del Tamaño del Conjunto de Datos:** La elección entre regresión logística y redes neuronales puede depender del tamaño del conjunto de datos. En conjuntos de datos pequeños, la regresión logística puede ser menos propensa al sobreajuste.\n",
    "\n",
    "# Comparaciones y Consideraciones Generales:\n",
    "- **Tamaño del Conjunto de Datos:**\n",
    "  - *Conjuntos Pequeños:* Modelos más simples como la regresión logística pueden ser preferibles para evitar sobreajuste en conjuntos de datos pequeños.\n",
    "  - *Conjuntos Grandes:* Modelos más complejos como las redes neuronales pueden aprovechar mejor conjuntos de datos grandes para aprender patrones más complejos.\n",
    "- **Complejidad del Problema:**\n",
    "  - *No Linealidades y Complejidades:* Problemas con patrones no lineales y relaciones complejas entre las características pueden beneficiarse de modelos más complejos como las redes neuronales.\n",
    "- **Interpretabilidad:**\n",
    "  - *Claridad de Coeficientes:* La regresión logística ofrece una interpretación clara de los coeficientes para cada característica, lo que puede ser crucial en aplicaciones donde la interpretabilidad es fundamental.\n",
    "  - *Complejidad de las Redes Neuronales:* Las redes neuronales pueden ser menos interpretables debido a su complejidad, y la interpretación de cómo las características contribuyen a las decisiones puede ser más desafiante.\n",
    "- **Tiempo de Entrenamiento:**\n",
    "  - *Modelos Complejos:* Modelos más complejos, como las redes neuronales profundas, pueden requerir más tiempo de entrenamiento, especialmente en conjuntos de datos grandes. Esto debe considerarse en aplicaciones donde el tiempo de entrenamiento es un factor crítico.\n",
    "- **Validación Cruzada:**\n",
    "  - *Evaluación del Rendimiento:* La validación cruzada es crucial para evaluar el rendimiento del modelo en diferentes conjuntos de datos y evitar el sobreajuste. Es especialmente importante en problemas con conjuntos de datos limitados.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766a2c82",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c423dc8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a96ef17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a1e7616",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44f2f750",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9d6bdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ea6a63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3539cb71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731dff0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
